{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data lake access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated SAS for csv\n",
    "sas_token = '<sas_token>'\n",
    "sas_uri ='<sas_url>'\n",
    "\n",
    "df = pd.read_csv(sas_uri) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen 1\n",
    "https://medium.com/azure-data-lake/using-jupyter-notebooks-and-pandas-with-azure-data-lake-store-48737fbad305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-mgmt-resource\n",
    "# !pip install azure-mgmt-datalake-store\n",
    "# !pip install azure-datalake-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep 'azure-datalake-store\\|azure-mgmt-datalake-store\\|azure-mgmt-resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "# https://github.com/Azure/azure-data-lake-store-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "# In entra create a new app and for that app a secret\n",
    "\n",
    "TENANT_ID = '<tenant_id>' \n",
    "CLIENT_SECRET = '<clinet_secret>' # client secret value\n",
    "CLIENT_ID = '<client_id>' # app id\n",
    "\n",
    "token = lib.auth(tenant_id=TENANT_ID,\n",
    "                 client_secret=CLIENT_SECRET,\n",
    "                 client_id=CLIENT_ID)\n",
    "token.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsFileSystemClient = core.AzureDLFileSystem(token, store_name='mystrgaccricgen1')\n",
    "adlsFileSystemClient\n",
    "\n",
    "# # Read a file into pandas dataframe\n",
    "with adlsFileSystemClient.open('/contg1/frutas.csv', 'rb') as f:\n",
    "    df = pd.read_csv(f) \n",
    "\n",
    "# # Show the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen2\n",
    "https://peter-hoffmann.com/2020/azure-data-lake-storage-gen-2-with-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-storage-file-datalake --pre\n",
    "# https://pypi.org/project/azure-storage-file-datalake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connection string from: stg account Access Keys \n",
    "connection_string = \"<connection_string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show files/folders in container\n",
    "from azure.storage.filedatalake import FileSystemClient\n",
    "\n",
    "file_system = FileSystemClient.from_connection_string(\n",
    "    connection_string, \n",
    "    file_system_name=\"cont2\")\n",
    "\n",
    "paths = file_system.get_paths()\n",
    "\n",
    "for path in paths:\n",
    "    print(path.name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file\n",
    "from azure.storage.filedatalake import DataLakeFileClient\n",
    "from io import StringIO\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas.csv\")\n",
    "\n",
    "\n",
    "data = file.download_file().read().decode('utf-8')\n",
    "print(data)\n",
    "df = pd.read_csv(StringIO(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_buf = StringIO()\n",
    "df.to_csv(s_buf)\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas2.csv\")\n",
    "file.create_file()\n",
    "file.append_data(data, offset=0)\n",
    "file.flush_data(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
