{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data lake access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated SAS for csv in container\n",
    "sas_token = '<sas_token>'\n",
    "sas_uri ='<sas_url>'\n",
    "\n",
    "df = pd.read_csv(sas_uri) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-storage-file-datalake --pre\n",
    "# https://pypi.org/project/azure-storage-file-datalake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connection string from: stg account Access Keys \n",
    "connection_string = \"<connection_string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show files/folders in container\n",
    "from azure.storage.filedatalake import FileSystemClient\n",
    "\n",
    "file_system = FileSystemClient.from_connection_string(\n",
    "    connection_string, \n",
    "    file_system_name=\"mycont\")\n",
    "\n",
    "paths = file_system.get_paths()\n",
    "\n",
    "for path in paths:\n",
    "    print(path.name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file\n",
    "from azure.storage.filedatalake import DataLakeFileClient\n",
    "from io import StringIO\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas.csv\")\n",
    "\n",
    "\n",
    "data = file.download_file().read().decode('utf-8')\n",
    "print(data)\n",
    "df = pd.read_csv(StringIO(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_buf = StringIO()\n",
    "df.to_csv(s_buf)\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas2.csv\")\n",
    "file.create_file()\n",
    "file.append_data(data, offset=0)\n",
    "file.flush_data(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-mgmt-resource\n",
    "# !pip install azure-mgmt-datalake-store\n",
    "# !pip install azure-datalake-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep 'azure-datalake-store\\|azure-mgmt-datalake-store\\|azure-mgmt-resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "# https://github.com/Azure/azure-data-lake-store-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "# In entra create a new app and for that app a secret\n",
    "\n",
    "TENANT_ID = '<tenant_id>' \n",
    "CLIENT_SECRET = '<clinet_secret>' # client secret value\n",
    "CLIENT_ID = '<client_id>' # app id\n",
    "\n",
    "token = lib.auth(tenant_id=TENANT_ID,\n",
    "                 client_secret=CLIENT_SECRET,\n",
    "                 client_id=CLIENT_ID)\n",
    "token.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsFileSystemClient = core.AzureDLFileSystem(token, store_name='mystrgaccricgen1')\n",
    "adlsFileSystemClient\n",
    "\n",
    "# # Read a file into pandas dataframe\n",
    "with adlsFileSystemClient.open('/contg1/frutas.csv', 'rb') as f:\n",
    "    df = pd.read_csv(f) \n",
    "\n",
    "# # Show the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-cosmosdb-table\n",
    "# https://learn.microsoft.com/en-us/azure/cosmos-db/table/quickstart-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmosdb.table.tableservice import TableService\n",
    "from azure.cosmosdb.table.models import Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_service = TableService(account_name='<storage_account_name>', account_key='<storage_account_key>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table\n",
    "table_service.create_table('mytable2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "def readTable(tableName):\n",
    "    tasks = table_service.query_entities(tableName)\n",
    "    tab = []\n",
    "    newrow = []\n",
    "    for row in tasks:\n",
    "        for ele in row:\n",
    "            newrow.append(row[ele])\n",
    "        tab.append(newrow)\n",
    "        newrow = []\n",
    "    return tab\n",
    "\n",
    "table = readTable('mytable')\n",
    "print(table)\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write table\n",
    "def setTable(tablename, table, table_service):\n",
    "    index = 0\n",
    "    for row in table:\n",
    "        task = {'PartitionKey': \"P\"+str(index), 'RowKey': \"R\"+str(index+1)}\n",
    "        index = index + 1\n",
    "        for ele in row:\n",
    "            task[\"Row\"+str(row.index(ele))] = ele\n",
    "        table_service.insert_entity(tablename, task)\n",
    "    return True\n",
    "\n",
    "\n",
    "df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [8, 7, 9]])\n",
    "list_of_lists = df.values.tolist()\n",
    "\n",
    "# inserting csv to cloud\n",
    "res = setTable('mytable', list_of_lists, table_service)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
