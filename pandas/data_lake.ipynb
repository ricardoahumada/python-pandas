{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data lake access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With a SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated SAS for csv\n",
    "sas_token = 'SAS_TOKEN'\n",
    "sas_uri ='SAS_URI'\n",
    "\n",
    "df = pd.read_csv(sas_uri) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen 1\n",
    "https://medium.com/azure-data-lake/using-jupyter-notebooks-and-pandas-with-azure-data-lake-store-48737fbad305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-mgmt-resource\n",
    "# !pip install azure-mgmt-datalake-store\n",
    "# !pip install azure-datalake-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep 'azure-datalake-store\\|azure-mgmt-datalake-store\\|azure-mgmt-resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.datalake.store import core, lib, multithread\n",
    "# https://github.com/Azure/azure-data-lake-store-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "# In entra create a new app and for that app a secret\n",
    "\n",
    "TENANT_ID = 'TENANT_ID ' \n",
    "CLIENT_SECRET = 'CLIENT_SECRET ' # client secret value\n",
    "CLIENT_ID = 'CLIENT_ID ' # app id\n",
    "\n",
    "token = lib.auth(tenant_id=TENANT_ID,\n",
    "                 client_secret=CLIENT_SECRET,\n",
    "                 client_id=CLIENT_ID)\n",
    "token.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adlsFileSystemClient = core.AzureDLFileSystem(token, store_name='mystrgaccricgen1')\n",
    "adlsFileSystemClient\n",
    "\n",
    "# # Read a file into pandas dataframe\n",
    "with adlsFileSystemClient.open('/contg1/frutas.csv', 'rb') as f:\n",
    "    df = pd.read_csv(f) \n",
    "\n",
    "# # Show the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SDK - gen2\n",
    "https://peter-hoffmann.com/2020/azure-data-lake-storage-gen-2-with-python.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-storage-file-datalake --pre\n",
    "# https://pypi.org/project/azure-storage-file-datalake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get connection string from: stg account Access Keys \n",
    "connection_string = \"connection_string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show files/folders in container\n",
    "from azure.storage.filedatalake import FileSystemClient\n",
    "\n",
    "file_system = FileSystemClient.from_connection_string(\n",
    "    connection_string, \n",
    "    file_system_name=\"cont2\")\n",
    "\n",
    "paths = file_system.get_paths()\n",
    "\n",
    "for path in paths:\n",
    "    print(path.name + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file\n",
    "from azure.storage.filedatalake import DataLakeFileClient\n",
    "from io import StringIO\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas.csv\")\n",
    "\n",
    "\n",
    "data = file.download_file().read().decode('utf-8')\n",
    "print(data)\n",
    "df = pd.read_csv(StringIO(data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': datetime.datetime(2025, 1, 21, 17, 18, 46, tzinfo=datetime.timezone.utc),\n",
       " 'etag': '\"0x8DD3A3FAA393478\"',\n",
       " 'last_modified': datetime.datetime(2025, 1, 21, 17, 18, 46, tzinfo=datetime.timezone.utc),\n",
       " 'content_length': 0,\n",
       " 'client_request_id': 'c51fc5f9-d81b-11ef-9add-cb2267dca560',\n",
       " 'request_id': '18fdde7a-d01f-003d-0228-6c1c41000000',\n",
       " 'version': '2025-01-05',\n",
       " 'request_server_encrypted': False,\n",
       " 'encryption_key_sha256': None,\n",
       " 'lease_renewed': None}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_buf = StringIO()\n",
    "df.to_csv(s_buf)\n",
    "\n",
    "file = DataLakeFileClient.from_connection_string(connection_string,\n",
    "                                                 file_system_name=\"cont2\", file_path=\"frutas2.csv\")\n",
    "file.create_file()\n",
    "file.append_data(data, offset=0)\n",
    "file.flush_data(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
