{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de los valores perdidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificar los valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/housing.csv')\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tabulate import tabulate\n",
    "rows_with_nan = df[df.isnull().any(axis=1)]\n",
    "print(tabulate(rows_with_nan, headers='keys'))\n",
    "print(rows_with_nan.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Opción de eliminar entrada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- O intentar imputar un valor razonable para ponerlo en su lugar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección y tratamiento de valores atípicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de muestra y adición de outliers\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "data = np.random.randint(low=0, high=11, size=1000)\n",
    "data[0] = 100\n",
    "data[1] = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcular los z-scores (https://en.wikipedia.org/wiki/Standard_score)\n",
    "- Identificar valores atípicos según z-cores (ej. 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = (data - np.mean(data)) / np.std(data) \n",
    "\n",
    "threshold = 3\n",
    "outliers = np.where(np.abs(z_scores) > threshold)[0]\n",
    "print(data[outliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otro método consiste en calcular el rango intercuartílico (IQR: https://en.wikipedia.org/wiki/Interquartile_range) de la distribución y clasificar cualquier valor que sea Q1-(1,5 x IQR) o Q3 + (1,5 x IQR) como valores atípicos potenciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular IQR\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Identificar outliers según IQR\n",
    "lower_bound = q1 - (1.5 * iqr)\n",
    "upper_bound = q3 + (1.5 * iqr)\n",
    "outliers = np.where((data < lower_bound) | (data > upper_bound))[0]\n",
    "print(data[outliers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento\n",
    "- Si se determinó que el valor atípico se debe a un error, simplemente corregir el error para resolver el valor atípico.\n",
    "- En otros casos, eliminar el valor atípico del conjunto de datos o sustituirlo por un valor menos extremo que conserve la forma general de la distribución.\n",
    "- **La limitación**: es un método en el que estableces un tope, o umbral, en la distribución de los datos y se sustituye cualquier valor fuera de esos límites por un valor especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de ejemplo\n",
    "data = {    'A': [100, 90, 85, 88, 110, 115, 120, 130, 140],    'B': [1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "df = pd.DataFrame(data) \n",
    "\n",
    "# Umbrales inferior y superior para la limitación (aquí los percentiles 5 y 95)\n",
    "umbral_inferior = df.quantile(0.05, numeric_only=True)\n",
    "umbral_superior = df.quantile(0.95, numeric_only=True)\n",
    "print('umbral_inferior:\\n',umbral_inferior)\n",
    "print('umbral_superior:\\n', umbral_superior)\n",
    "\n",
    "# Limitar valores atípicos\n",
    "capped_df = df.clip(lower=umbral_inferior, upper=umbral_superior, axis=1)\n",
    "print(\"DataFrame original:\")\n",
    "print(df)\n",
    "print(\"\\nDataFrame limitado:\")\n",
    "print(capped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En algunos casos, se puede transformar los datos de forma que los valores atípicos tengan menos impacto, como una transformación de raíz cuadrada o una transformación logarítmica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precauciones\n",
    "- **Comprende la distribución de datos subyacente**: Antes de aplicar cualquier transformación, es importante comprender la distribución de tus datos y cómo influirán en ella determinadas transformaciones.\n",
    "- **Elige una transformación adecuada**: Selecciona un método de transformación adecuado a tu distribución de datos.\n",
    "- **Maneja ceros y valores negativos**: Algunas transformaciones pueden no ser adecuadas para datos que contengan ceros o valores negativos. Añadir una pequeña constante puede ayudar a evitar problemas al tomar logaritmos, por ejemplo.\n",
    "- **Valida los datos transformados**: Tras aplicar las transformaciones, valida los datos transformados para asegurarte de que la distribución resultante cumple los supuestos de tu análisis.\n",
    "- **Considera la interpretabilidad**: Los datos transformados pueden no ser tan fácilmente interpretables como los datos originales. Asegúrate de que las partes interesadas comprenden las implicaciones de la transformación en la interpretación de los resultados.\n",
    "\n",
    "**Lecturas recomensdadas**:\n",
    "- https://github.com/francomanca93/fundamentos-de-estadistica-con-python\n",
    "- https://datos.gob.es/sites/default/files/doc/file/guia_eda_python.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de duplicados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizando el método duplicated() de la biblioteca pandas de Python, puedes identificar fácilmente las filas duplicadas en un DataFrame para examinarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/housing.csv')\n",
    "df =pd.concat([df,df.iloc[[1,60,6]]])\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(duplicate_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La mayoría de los duplicados pueden ser copias exactas y pueden eliminarse simplemente utilizando el método drop_duplicates() de Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.drop_duplicates()\n",
    "duplicate_rows = cleaned_df[cleaned_df.duplicated()]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En algunos casos, puede ser más apropiado fusionar registros duplicados, agregando información. \n",
    "    - Por ejemplo, si los duplicados representan varias entradas para la misma entidad, podemos fusionarlos utilizando funciones de agregación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'customer_id' : [102, 102, 101, 103, 102],'product_id' : ['A', 'B', 'A', 'C', 'B'],'quantity_sold' : [5, 3, 2, 1, 4]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df,'\\n')\n",
    "\n",
    "merged_df = df.groupby(['customer_id', 'product_id']).agg({'quantity_sold': 'sum'}).reset_index()\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratar las incoherencias\n",
    "- Los distintos tipos de incoherencias requerirán soluciones diferentes. Las incoherencias derivadas de la introducción de datos incorrectos o de erratas pueden tener que ser corregidas por una fuente experta. Otra posibilidad es sustituir los datos incorrectos mediante imputación, como si se tratara de un valor omitido, o eliminarlos por completo del conjunto de datos, según las circunstancias.\n",
    "\n",
    "- Las incoherencias en el formato de los datos pueden corregirse utilizando algunos métodos de normalización. Para eliminar los espacios iniciales y finales de una cadena, puedes utilizar el método .strip(). Los métodos .upper() y .lower() normalizarán las mayúsculas y minúsculas en las cadenas. Y la conversión de fechas a datetimes mediante pd.to_datetime normalizará el formato de las fechas.\n",
    "\n",
    "- También se debe asegurar de que cada valor de la columna es del mismo tipo usando: **.astype()**.\n",
    "\n",
    "- Otras correcciones de incoherencias de formato que se pueden necesitar llevar a cabo son:\n",
    "    - Conversión de unidades\n",
    "    - Normalización del correo electrónico, el teléfono y la dirección\n",
    "    - Eliminar la puntuación de las cadenas\n",
    "    - Utilizar el mapeo de valores para tratar las abreviaturas comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mapping = {'M': 'Male', 'F': 'Female'}\n",
    "standardized_value = value_mapping.get('M', 'Unknown')\n",
    "print(standardized_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
